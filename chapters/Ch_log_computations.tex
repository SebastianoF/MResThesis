\chapter{Log-Algorithm using Log-composition}\label{ch:log_algorithm}

\begin{flushright}
	I think you might do something better with the time \\ than wasting it in asking riddles that have no answers. \\ -\emph{Alice in Wonderland.}
\end{flushright}

\vspace{0.5 cm}

\noindent
The \emph{logarithm computation problem} can be stated as follows:
\begin{center}
\emph{
	Given $p$ in a Lie group $\mathbb{G}$, \\ 
	what is the element $\mathbf{u}$ in its Lie algebra $\mathfrak{g}$ \\
	such that $\exp(\mathbf{u}) = p$ ?  
}
\end{center}
There are several numerical methods to compute the approximation of the problem's solution. Arsigny, who first pointed the applications of the Lie logarithm in medical image registration in\cite{Arsigny:MRM:06} and \cite{arsigny2006bi}, proposed the Inverse scaling and squaring. Here we are interested in the numerical iterative algorithm for the computation of the Lie logarithm, called here \emph{log-algorithm}, presented for the first time in \cite{Bossa:08}. In this chapter we present a strong relation between the log-algorithm and the log-composition: in consequence of this, each numerical methods presented in these pages can be applied to find a numerical method to solve the logarithm computation problem.\\
The first step toward this direction is to introduce the space of the approximations of a Lie algebra and a the Lie group.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % SUBSECTION
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\section{Spaces of Approximations}\label{se:space_of_approximation}

\noindent
As seen in section \ref{se:rigid_body_transformations} of the previous chapter for the particular case of $SE(2)$, if the matrix $dr$ is small enough we can approximate $\exp(dr)$ with $1 + dr$. Aim of this section is to generalize the same approximation for the SVF.  \\
We define two approximating functions:
\begin{align*}
\text{app} : \mathfrak{g} & \longrightarrow  \mathfrak{g} ^{\sim}    \\
\mathbf{u} &\longmapsto \exp(\mathbf{u}) - 1
\end{align*}
\begin{align*}
\text{App} : \mathbb{G} & \longrightarrow  \mathbb{G}^{\sim}   \\
\exp(\mathbf{u}) &\longmapsto 1 + \mathbf{u}
\end{align*}
Where $\mathfrak{g} ^{\sim}$ is the space of approximations of elements of $\mathfrak{g} $, and $\mathbb{G}^{\sim} $ is the space of approximations of elements in $\mathbb{G}$, defined as
\begin{align*}
\mathfrak{g} ^{\sim} & := \{ \exp(\mathbf{u}) - 1 \mid \mathbf{u}\in \mathfrak{g}\} \cup \mathfrak{g} \\
\mathbb{G}^{\sim}  & := \{ 1 + \mathbf{u} \mid \mathbf{u}\in \mathbb{G}\} \cup \mathbb{G} \\
\end{align*}
In general $\mathfrak{g} ^{\sim} \neq \mathfrak{g}$ and $\mathbb{G}^{\sim} \neq \mathbb{G}$, but in the considered cases of $\mathfrak{se}(2)$ and SVF, when $\mathbf{u}$ is \emph{small enough}
it follows that $\exp(\mathbf{u}) - 1 \in \mathfrak{g} $ and $1 + \mathbf{u}\in\mathbb{G}$. Therefore the elements of $\mathfrak{g}^{\sim} $ are compatible with all of the operations of Lie algebra $\mathfrak{g}$ and the elements of $\mathbb{G}^{\sim}$ are compatible with all of the operations of Lie group $\mathbb{G}$.\\
Lets examine what does \emph{small enough} means in these two cases:
\begin{enumerate}
	\item[$\mathfrak{se}(2)$ -] Since $\mathfrak{se}(2)$ and $SE(2)$ are subset of the bigger algebra $SE(2)$ then exp and log can be defined as infinite series. From 
	\begin{align*}
	\exp(\mathbf{u}) = I + \mathbf{u} + O(\mathbf{u}^2) 
	\end{align*}
	It follows that $\text{app}(\mathbf{u}) - \mathbf{u} = O(\mathbf{u}^2)$. Thus for all $\mathbf{u}$ smaller than $\delta$ for any norm, exists $M(\delta)$ such that
	\begin{align*}
	\euclideanMetric{\text{app}(\mathbf{u}) - \mathbf{u} } < M(\delta) \euclideanMetric{\mathbf{u}^2}
	\end{align*}
	\item[SVF -] In case of SVF we do not have any Taylor series and big-O notation available but, according to the proposition 8.6 at page 163 of \cite{younes2010shapes}, if $\mathbf{u}$ is, for any norm, smaller than $\epsilon<1/C$, where $C$ is the Lipschitz constant of the same norm, then $e + \mathbf{u}$ is a diffeomorphism. With this condition holds that
	$\text{SVF}^{\sim} = \text{SVF}$. 
\end{enumerate}

\noindent
Therefore, for each small enough $\mathbf{u}$ in $\mathfrak{se}(2)$ or SVF, 
and considering the definition of the log-composition (equation \ref{eq:main_def_log_composition}) 
the following properties holds:
\begin{enumerate}
	\item The approximations $\mathbf{u} \simeq   \text{app} (\mathbf{u})$, $\exp(\mathbf{u}) \simeq   \text{App} (\exp(\mathbf{u})) $ are meaningful.
	\item $\mathbf{u} = \mathbf{v} \oplus (-\mathbf{v} \oplus  \mathbf{u} )$
	\item $\text{app} (\mathbf{v} \oplus  \mathbf{u}) = \exp(\mathbf{v})\exp(\mathbf{u}) - 1 \in \mathfrak{g} ^{\sim}$
\end{enumerate}

\noindent
With this machinery, we can finally reformulate the algorithm presented in \cite{Bossa:08} for the numerical computation of the Lie logarithm map using the log-composition.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % SUBSECTION
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\section{The Log-computation Algorithm using Log-composition}

If the goal is to find $\mathbf{u}$ when its exponential is known, we can consider the sequence transformations $\{\mathbf{u}_{j}  \}_{j=0}^{\infty}$ that approximate $\mathbf{u}$ as consequence of
\begin{align*}
\mathbf{u} = \mathbf{u}_{j} \oplus  (-\mathbf{u}_{j}  \oplus  \mathbf{u} ) \Longrightarrow
\mathbf{u} \simeq \mathbf{u}_{j} \oplus  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )
\end{align*}
This suggest that a reasonable approximation for the $(j+1)$-th element of the series can be defined by
\begin{align*}
\mathbf{u}_{j+1} & :=  \mathbf{u}_{j} \oplus  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )
\end{align*}
If we chose the initial value $\mathbf{u}_{0}$ to be zero, then the algorithm presented in \cite{Bossa:08}  become:
%\begin{align*}
%p= \exp(\mathbf{v}) &= (\exp(\mathbf{v})\circ \exp(-\mathbf{v}))\circ \exp(\mathbf{v})\\
%&= \exp(\mathbf{v})\circ (\exp(-\mathbf{v})\circ p)\\
%&= \exp(\mathbf{v})\circ \exp(\delta \mathbf{v})\\
%&\approx \exp(\mathbf{v})\circ \exp(\tilde{\delta} \mathbf{v})
%\end{align*}
\begin{equation}\label{eq:bossa_reformulated}
\begin{cases}
\mathbf{u}_0 = 0 \\
\mathbf{u}_{j+1} = \mathbf{u}_{j} \oplus  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )
\end{cases}
\end{equation}
Each strategy that we have examined to compute the Lie composition, become a numerical method for the computation of the logarithm.
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % SUBSECTION
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\subsection{Truncated BCH Strategy}
At each step, we compute the approximation $\mathbf{v}_{j+1}$ with the $k$-th truncation of the BCH formula:
\begin{equation}\label{eq:bossa_bch_strat}
\begin{cases}
\mathbf{u}_0 = 0 \\
\mathbf{u}_{j+1} = \text{BCH}^{k}(\mathbf{u}_{j}, \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} ))
\end{cases}
\end{equation}
For $k = 0$, the approximation $\mathbf{u}_{j+1}$ results simply the sum $\mathbf{u}_{j} + \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )$. When $k=1$, it results 
\begin{align*}
\text{BCH}^{1}(\mathbf{u}_{j}, \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} ))
&=
\mathbf{u}_{j} +  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )\\
&=
\mathbf{u}_{j} + \exp(-\mathbf{u}_{j}) \exp( \mathbf{u})  - 1
\end{align*}
And $k=2$ it follows
\begin{align*}
\text{BCH}^{2}(\mathbf{u}_{j}, \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} ))
&=
\mathbf{u}_{j} +  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} ) + \frac{1}{2}[\mathbf{u}_{j},  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )]\\
&=
\mathbf{u}_{j} + \exp(-\mathbf{u}_{j}) \exp( \mathbf{u})  - 1 + \\
&+ \frac{1}{2}(  \mathbf{u}_{j}( \exp(-\mathbf{u}_{j}) \exp( \mathbf{u})  - 1) -  ( \exp(-\mathbf{u}_{j}) \exp( \mathbf{u})  - 1)\mathbf{u}_{j})
\end{align*}

The following theorem presented in \cite{Bossa:08}, provides an error bound when $k = \infty$ so when the BCH formula is used, instead one of its truncation.
\begin{theorem}[Bossa]\label{th:bossa}
	The iterative algorithm 
	\begin{equation}
	\begin{cases}
	\mathbf{u}_0 = 0 \\
	\mathbf{u}_{j+1} %= \text{BCH}(\mathbf{u}_{j}, \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} ))
	                          = \mathbf{u}_{j} \oplus  \text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )
	\end{cases}
	\end{equation}
	converges to $\mathbf{v}$ with error $\delta_n \in \mathbb{G}$, where
	\begin{align*}
	\delta_{n} := \log(\exp(\mathbf{v})\circ \exp(-\mathbf{v}_{n})) \in O(\euclideanMetric{p - e}^{2^{n}})
	\end{align*}
\end{theorem}

We observe that this upper limit can be computed only when a closed-form for the log-composition is available, as for example $\mathfrak{se}(2)$.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % SUBSECTION
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\subsection{Parallel Transport Strategy}

If we apply the parallel transport method for the computation of the log-composition, we obtain another version of the log-algorithm:
\begin{equation}\label{eq:bossa_parallel_strategy}
\begin{cases}
\mathbf{u}_0 = \mathbf{0} \\
\mathbf{u}_{t} = \mathbf{u}_{t-1} + \exp(\frac{\mathbf{u}_{t-1}}{2}) \circ \exp(\delta \mathbf{u}_{t-1}) \circ \exp(-\frac{\mathbf{u}_{t-1}}{2}) - e
\end{cases}
\end{equation}
We notice that mixing the operation of composition, sum and scalar product makes sense when the involved vectors are \emph{small enough}, as stated in \ref{se:space_of_approximation}. 
Analytical computation of an upper bound error is not straightforward in this case. See section \ref{ch:conclusions} for further details and other possible researches.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % SUBSECTION
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\subsection{Symmetrization Strategy}
The algorithm \ref{eq:bossa_reformulated} could have been reformulated alternatively as $\mathbf{u}_{j+1} =    \text{app}(\mathbf{u} \oplus  - \mathbf{u}_{j}  ) \oplus \mathbf{u}_{j}$. The log-composition is not symmetric therefore the two version in some cases may not return the same value. In an attempt to move toward the solution of this issue we consider
\begin{equation}\label{eq:bossa_symmetric}
\begin{cases}
\mathbf{u}_0 = 0 \\
\mathbf{u}_{j+1} = \mathbf{u}_{j} \oplus 
\frac{1}{2}
\big(  
\text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )
+
\text{app}(\mathbf{u} \oplus  - \mathbf{u}_{j}  )
\big)
\end{cases}
\end{equation}
Writing directly the approximations and using the BCH approximation of degree $1$ it become:
\begin{equation}
\begin{cases}
\mathbf{u}_0 = 0 \\
\mathbf{u}_{j+1} 
%= \mathbf{u}_{j} +  
%\frac{1}{2}
%\big(  
%\text{app}(-\mathbf{u}_{j}  \oplus  \mathbf{u} )
%+
%\text{app}(\mathbf{u} \oplus  - \mathbf{u}_{j}  )
%\big)
=
\mathbf{u}_{j} +  
\frac{1}{2}
\big(  
\exp(-\mathbf{u}_{j})  \exp(\mathbf{u} ) - e
+
\exp(\mathbf{u}) \exp(-\mathbf{u}_{j}) - e
\big)
\end{cases}
\end{equation}
Experimental results of the methods presented in this section are presented in the next chapter. %\ref{ch:results}. %We conclude this one, noticing that any time the Lie algebra $\mathfrak{g}$ and the Lie group $\mathbb{G}$ are subset of a bigger algebra (and therefore the operation of composition is compatible with the sum and with the scalar product), then approximations $\text{app}(\mathbf{u}  \oplus  -\mathbf{v} )$ and $\text{app}(-\mathbf{v}  \oplus  \mathbf{u} )$ are related by the equation
%\begin{align*}
%\text{app}(\mathbf{u}  \oplus  -\mathbf{v} )\exp(\mathbf{v})
%\end{align*}











%
%The algorithm for the computation of the group logarithm can be improved considering a symmetric version of the underpinning strategy. In this version we use the first order approximation of the BCH formula (see equation (\ref{eq:first_order_approx}) in the following proof), compensating with the fact that the symmetrization should decrease the error involved.
%It gives birth to the following algorithm:
%\begin{equation}\label{eq:sym_strategy}
%\begin{cases}
%\mathbf{v}_0 = \mathbf{0} \\
%\mathbf{v}_{t+1} = \mathbf{v}_{t} + \frac{1}{2}(\tilde{\delta} \mathbf{v}^{L}_{t} +\tilde{\delta} \mathbf{v}^{R}_{t})
%\end{cases}
%\end{equation}
%Where $\tilde{\delta} \mathbf{v}^{R}_{t} = \exp(\mathbf{v})\circ \exp(- \mathbf{v}_{t}) - e$ and $\tilde{\delta} \mathbf{v}^{L}_{t} = \exp(-\mathbf{v}_{t})\circ \exp(\mathbf{v}) - e$.\\
%\begin{proof}
%	To show why it works we remind that the starting point was
%	\begin{align*}
%	p= \exp(\mathbf{v}) &=  \exp(\mathbf{v}_{0})\circ \exp(\delta \mathbf{v}_{0})
%	\end{align*}
%	where $\exp(\delta \mathbf{v}_{0}) = \exp(-\mathbf{v}_{0})\circ p$.\\
%	An equivalent starting point would have been $\exp(\mathbf{v}) = \exp(\delta \mathbf{v})\circ \exp(\mathbf{v}_{0})$ for $\exp(\delta \mathbf{v}) = p\circ \exp(-\mathbf{v}_{0})$. \\
%	This idea leads to the definition of
%	\begin{align*}
%	\exp(\delta \mathbf{v}^{R}_{t}) &:= p\circ \exp(- \mathbf{v}_{t}) = \exp(\mathbf{v})\circ \exp(- \mathbf{v}_{t})\\
%	\exp(\delta \mathbf{v}^{L}_{t}) &:=  \exp(- \mathbf{v}_{t}) \circ p = \exp(- \mathbf{v}_{t}) \circ \exp(\mathbf{v}) 
%	\end{align*}
%	It follows that 
%	\begin{align*}
%	\exp(\mathbf{v}) &= \exp(\mathbf{v}_{0})\circ \exp(\delta \mathbf{v}^{R}_{0})\\
%	\exp(\mathbf{v}) &=  \exp(\delta \mathbf{v}^{L}_{0}) \circ \exp(\mathbf{v}_{0})
%	\end{align*}
%	Using $\exp(\delta \mathbf{v}^{R}_{t}) \approx e + \delta \mathbf{v}^{R}_{t}$ and $\exp(\delta \mathbf{v}^{L}_{t}) \approx e + \delta \mathbf{v}^{L}_{t}$ we can use the following approximation to define the symmetric algorithm:
%	\begin{align*}
%	\exp(\delta \mathbf{v}^{R}_{t}) &= \exp(\mathbf{v})\circ \exp(-\mathbf{v}_{t})\\
%	e + \tilde{\delta} \mathbf{v}^{R}_{t} &= \exp(\mathbf{v})\circ \exp(- \mathbf{v}_{t})\\
%	\tilde{\delta} \mathbf{v}^{R}_{t} &= \exp(\mathbf{v})\circ \exp(- \mathbf{v}_{t}) - e
%	\end{align*}
%	\begin{align*}
%	\exp(\delta \mathbf{v}^{L}_{t}) &= \exp(- \mathbf{v}_{t}) \circ \exp(\mathbf{v})\\
%	e + \tilde{\delta} \mathbf{v}^{L}_{t} &= \exp(-\mathbf{v}_{t})\circ \exp( \mathbf{v})\\
%	\tilde{\delta} \mathbf{v}^{L}_{t} &= \exp(-\mathbf{v}_{t})\circ \exp(\mathbf{v}) - e
%	\end{align*}
%	Which gives birth to iterative algorithm, for a given initial value $V_0$:  
%	\begin{equation}
%	\begin{cases}
%	\mathbf{v}_0  \\
%	\mathbf{v}_{t+1} =\text{BCH}(\mathbf{v}_{t},\tilde{\delta} \mathbf{v}^{R}_{t})
%	\end{cases}
%	\begin{cases}
%	\mathbf{v}_0  \\
%	\mathbf{v}_{t+1} = \text{BCH}(\tilde{\delta} \mathbf{v}^{L}_{t}, \mathbf{v}_{t})
%	\end{cases}
%	\end{equation}
%	If follows that
%	\begin{align*}
%	\mathbf{v}_{t+1} = \frac{1}{2}(\text{BCH}(\tilde{\delta} \mathbf{v}^{L}_{t}, \mathbf{v}_{t}) + \text{BCH}(\mathbf{v}_{t},\tilde{\delta} \mathbf{v}^{R}_{t}))
%	\end{align*}
%	Taking the first order approximation of the BCH formula:
%	\begin{align}\label{eq:first_order_approx}
%	BCH(\tilde{\delta} \mathbf{v}^{L}_{t}, \mathbf{v}_{t}) &\approx \tilde{\delta} \mathbf{v}^{L}_{t} + \mathbf{v}_{t}\\
%	BCH(\mathbf{v}_{t},\tilde{\delta} \mathbf{v}^{R}_{t}) &\approx \mathbf{v}_{t} + \tilde{\delta} \mathbf{v}^{R}_{t}
%	\end{align}
%	we get
%	\begin{align*}
%	\mathbf{v}_{t+1} = \mathbf{v}_{t} + \frac{1}{2}(\tilde{\delta} \mathbf{v}^{L}_{t} + \tilde{\delta} \mathbf{v}^{R}_{t})
%	\end{align*}
%\end{proof}
%We observe that the symmetric approach do not requires to use the BCH formula at each passage, having considered the approximation at the first order of the BCH.\\
%We conclude with a formula that relates $\tilde{\delta} \mathbf{v}^{L}_{t}$ with $\tilde{\delta} \mathbf{v}^{R}_{t}$:
%\begin{theorem}
%	Be $\tilde{\delta} \mathbf{v}^{R}_{t} = \exp(\mathbf{v})\circ \exp(- \mathbf{v}_{t}) - e$ and $\tilde{\delta} \mathbf{v}^{L}_{t} = \exp(-\mathbf{v}_{t})\circ \exp(\mathbf{v}) - e$ as before, then
%	\begin{align*}
%	\delta \mathbf{v}^{L}_{t} \approx \exp(-\mathbf{v}_{t}) \circ \delta \mathbf{v}^{R}_{t} \circ \exp(\mathbf{v}_{t})
%	\end{align*}
%\end{theorem}
%\begin{proof}
%	Since $\exp(\mathbf{v}_{t})\circ \exp(\delta \mathbf{v}^{R}_{t}) \approx exp(\delta \mathbf{v}^{L}_{t}) \circ \exp(\mathbf{v}_{t})$ it follows
%	\begin{align*}
%	\exp(\delta \mathbf{v}^{R}_{t}) = \exp(-\mathbf{v}_{t})\circ \delta \mathbf{v}^{L}_{t} \circ \exp(\mathbf{v}_{t})
%	\end{align*}
%	Using $\exp(\delta \mathbf{v}^{R}_{t}) = e + \delta \mathbf{v}^{R}_{t}$ and $\exp(\delta \mathbf{v}^{L}_{t}) = e + \delta \mathbf{v}^{L}_{t}$ we get
%	\begin{align*}
%	e + \delta \mathbf{v}^{R}_{t} &= \exp(-\mathbf{v}_{t})\circ (e + \delta \mathbf{v}^{L}_{t}) \circ \exp(\mathbf{v}_{t})\\
%	\delta \mathbf{v}^{R}_{t} &= \exp(-\mathbf{v}_{t})\circ \delta \mathbf{v}^{L}_{t} \circ \exp(\mathbf{v}_{t})
%	\end{align*}
%\end{proof}
%
%

%
%% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%% % SUBSECTION
%% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%\subsubsection{Symmetric-Parallel Transport Strategy}
%If we are not satisfied to having take only the firs order approximation of the BCH in the equation (\ref{eq:first_order_approx}) we use at this stage the parallel transport in the method presented in this subsection.
%Going back to the algorithm \ref{eq:sym_strategy} we can apply to
%\begin{align*}
%\mathbf{v}_{t+1} = \frac{1}{2}(\text{BCH}(\tilde{\delta} \mathbf{v}^{L}_{t}, \mathbf{v}_{t}) + \text{BCH}(\mathbf{v}_{t},\tilde{\delta} \mathbf{v}^{R}_{t}))
%\end{align*}
%the parallel transport to get
%\begin{align*}
%\mathbf{v}_{t+1} &= \frac{1}{2}((\tilde{\delta} \mathbf{v}^{L}_{t})^{\parallel} + \mathbf{v}_{t} + \mathbf{v}_{t} + (\tilde{\delta} \mathbf{v}^{R}_{t})^{\parallel}) \\
%&= 2\mathbf{v}_{t} + \frac{1}{2}((\tilde{\delta} \mathbf{v}^{L}_{t})^{\parallel} + (\tilde{\delta} \mathbf{v}^{R}_{t})^{\parallel})
%\end{align*}
%Applying the definition of parallel transport we get
%\begin{align*}
%(\tilde{\delta} \mathbf{v}^{L}_{t})^{\parallel} + (\tilde{\delta} \mathbf{v}^{R}_{t})^{\parallel} 
%= 
%\exp(-\frac{\mathbf{v}_{t}}{2}) \circ (\tilde{\delta} \mathbf{v}^{L}_{t} +\tilde{\delta} \mathbf{v}^{R}_{t} )\circ \exp(\frac{\mathbf{v}_{t}}{2})
%\end{align*}
%where 
%\begin{align*}
%\tilde{\delta} \mathbf{v}^{L}_{t} &=  \exp(\mathbf{v})\circ \exp(-\mathbf{v}_{t}) - e \\
%\tilde{\delta} \mathbf{v}^{R}_{t} &=  \exp(-\mathbf{v}_{t})\circ \exp(\mathbf{v}) - e
%\end{align*}
%Then a new improvement of the algorithm \ref{eq:bossa_strategy}  is
%\begin{equation}\label{eq:sym_parallel_strategy}
%\begin{cases}
%\mathbf{v}_0 = 0 \\
%\mathbf{v}_{t} 
%=  
%2\mathbf{v}_{t-1} + \frac{1}{2}(\exp(-\frac{\mathbf{v}_{t-1}}{2}) 
%\circ 
%(\tilde{\delta} \mathbf{v}^{L}_{t-1} +\tilde{\delta} \mathbf{v}^{R}_{t-1} )\circ \exp(\frac{\mathbf{v}_{t-1}}{2}))
%\end{cases}
%\end{equation}
%(This must be investigated!)





