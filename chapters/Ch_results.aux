\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{hunter2007}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experimental Results}{37}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:results}{{5}{37}{Experimental Results}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Log-composition for $\mathfrak  {se}(2)$}{37}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Methods and Results}{37}{subsection.5.1.1}}
\citation{misner1973gravitation}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Comparison of the errors for each numerical method to compute the Log-composition $dr_{0} \oplus dr_{1}$ in $\mathfrak  {se}(2)$. Truncated BCH of degrees 0,1,2, parallel transport method and Taylor method are considered for different values of the norm of $dr_{1}$ (x-axes) and norm of $dr_{0}$ (y-axes). The value of each square corresponds to the average error of 500 random samples in each of the 6 sub-intervals between $0.1$ and $2.0$. Errors with BCH 0 and parallel transport method are comparable, but the parallel transport method is not symmetric and has better performance when $dr_{1}$ is small. BCH 1 and Taylor are comparable as well and they are both symmetric, but the best performance in terms of approximation is the BCH 2. Values of the sub-square under the \emph  {gray arrows} are shown in the boxplot \ref  {fig:se2_image_scale} where variance, quartiles and outliers are visualized. }}{38}{figure.5.1}}
\newlabel{fig:se2_image_scale}{{5.1}{38}{Comparison of the errors for each numerical method to compute the Log-composition $dr_{0} \oplus dr_{1}$ in $\mathfrak {se}(2)$. Truncated BCH of degrees 0,1,2, parallel transport method and Taylor method are considered for different values of the norm of $dr_{1}$ (x-axes) and norm of $dr_{0}$ (y-axes). The value of each square corresponds to the average error of 500 random samples in each of the 6 sub-intervals between $0.1$ and $2.0$. Errors with BCH 0 and parallel transport method are comparable, but the parallel transport method is not symmetric and has better performance when $dr_{1}$ is small. BCH 1 and Taylor are comparable as well and they are both symmetric, but the best performance in terms of approximation is the BCH 2. Values of the sub-square under the \emph {gray arrows} are shown in the boxplot \ref {fig:se2_image_scale} where variance, quartiles and outliers are visualized}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Errors of the numerical methods for the computation of the Log-composition of $dr_{0} \oplus dr_{1}$ in $\mathfrak  {se}(2)$. Norm of $dr_{0}$ is in the interval $[0.37,1.05]$, norm of $dr_{1}$ in the interval $[0.1, 1.05]$ divided in 3 segments. Mean values of each box are shown in the first row in different colors. Shown data corresponds to a section of the image scale \ref  {fig:se2_image_scale}, indicated by a gray arrow. As expected all of the error means increase with the of norm of $dr_1$, but the rate of the growth is different for each method.}}{39}{figure.5.2}}
\newlabel{fig:se2_boxplot}{{5.2}{39}{Errors of the numerical methods for the computation of the Log-composition of $dr_{0} \oplus dr_{1}$ in $\mathfrak {se}(2)$. Norm of $dr_{0}$ is in the interval $[0.37,1.05]$, norm of $dr_{1}$ in the interval $[0.1, 1.05]$ divided in 3 segments. Mean values of each box are shown in the first row in different colors. Shown data corresponds to a section of the image scale \ref {fig:se2_image_scale}, indicated by a gray arrow. As expected all of the error means increase with the of norm of $dr_1$, but the rate of the growth is different for each method}{figure.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Log-composition for SVF}{39}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Methods: random generated SVF.}{39}{subsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Random generated vector field before and after the Gaussian smoother: in the first row a random generated vector field of dimension $50\times 50 \times 2$ where the value at each pixel are sampled from a random variable with normal distribution of mean $0$ and sigma $4$. The second row shows the same random vector field after a Gaussian smoothing of sigma $2$ (the code is based on the scipy library ndimage.filters.gaussian\textunderscore filter). In the last column shows the quiver of the vector field in the squared subregion of size $10\times 10$ at the point $(20,20)$. From the colorscale it is also possible to see that the values distribution of the filtered image is not anymore symmetric. }}{40}{figure.5.3}}
\newlabel{fig:SVF_gaussian_smoothing_effects}{{5.3}{40}{Random generated vector field before and after the Gaussian smoother: in the first row a random generated vector field of dimension $50\times 50 \times 2$ where the value at each pixel are sampled from a random variable with normal distribution of mean $0$ and sigma $4$. The second row shows the same random vector field after a Gaussian smoothing of sigma $2$ (the code is based on the scipy library ndimage.filters.gaussian\textunderscore filter). In the last column shows the quiver of the vector field in the squared subregion of size $10\times 10$ at the point $(20,20)$. From the colorscale it is also possible to see that the values distribution of the filtered image is not anymore symmetric}{figure.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Relationship between the initial standard deviation $\sigma _{\text  {init}}$ that defines the random SVF (stationary velocity field), the standard deviation of the Gaussian filter $\sigma _{\text  {gf}}$ utilized to regularize the SVF and its norm. Figure (a) represents schematically the two factors that define the norm of an SVF and with the blue dots we emphasized the values that has been chosen for the numerical computations proposed in (b) and (c). Figure (b) shows the mean of the norm of $10$ random generated SVF, as element of a Lie group, with initial standard deviation $\sigma _{\text  {init}}$ (on the x-axis) and Gaussian filter with standard deviation $\sigma _{\text  {gf}}$ (in different colors). Figure (c) shows the norm of the same element after exponentiating and so after having them in the Lie algebra. It is important to remark that it is not possible in general define a norm on a group. Nevertheless for matrices and for SVF it is possible to extend the norm from the Lie algebra to the Lie group, as proposed in chapter \ref  {ch:spatial_transformations} with the definition of displacement field norm (DS-norm). }}{41}{figure.5.4}}
\newlabel{fig:SVF_sigma_means_comparisons}{{5.4}{41}{Relationship between the initial standard deviation $\sigma _{\text {init}}$ that defines the random SVF (stationary velocity field), the standard deviation of the Gaussian filter $\sigma _{\text {gf}}$ utilized to regularize the SVF and its norm. Figure (a) represents schematically the two factors that define the norm of an SVF and with the blue dots we emphasized the values that has been chosen for the numerical computations proposed in (b) and (c). Figure (b) shows the mean of the norm of $10$ random generated SVF, as element of a Lie group, with initial standard deviation $\sigma _{\text {init}}$ (on the x-axis) and Gaussian filter with standard deviation $\sigma _{\text {gf}}$ (in different colors). Figure (c) shows the norm of the same element after exponentiating and so after having them in the Lie algebra. It is important to remark that it is not possible in general define a norm on a group. Nevertheless for matrices and for SVF it is possible to extend the norm from the Lie algebra to the Lie group, as proposed in chapter \ref {ch:spatial_transformations} with the definition of displacement field norm (DS-norm)}{figure.5.4}{}}
\newlabel{eq:angular_coefficients_for_the_gf}{{5.1}{41}{Methods: random generated SVF}{equation.5.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Mean errors for the numerical computation of the Log-composition of randomly generated stationary velocity fields (SVF). Initial standard deviations of the SVF $\sigma _{\text  {init}}^{0}$ and $\sigma _{\text  {init}}^{1}$ are given by the values on the axis for each sampling of $15$ elements. The error is computed without a ground truth according to the formula \ref  {eq:error_svf_sythetic_data}. When the norm of $\mathbf  {u}_1$ is small (see figure \ref  {fig:SVF_sigma_means_comparisons} to infer the norm from the standard deviations), parallel transport method and truncated BCH of degree 1 have comparable results, but parallel transport, as expected from the formula, is not symmetric respect to the size of the input vectors. Results of another sampling with the value of $\sigma _{\text  {init}}^{0}$ and $\sigma _{\text  {init}}^{1}$ are shown in figure \ref  {fig:SVF_scatter_plot}.}}{42}{figure.5.5}}
\newlabel{fig:SVF_image_scale}{{5.5}{42}{Mean errors for the numerical computation of the Log-composition of randomly generated stationary velocity fields (SVF). Initial standard deviations of the SVF $\sigma _{\text {init}}^{0}$ and $\sigma _{\text {init}}^{1}$ are given by the values on the axis for each sampling of $15$ elements. The error is computed without a ground truth according to the formula \ref {eq:error_svf_sythetic_data}. When the norm of $\mathbf {u}_1$ is small (see figure \ref {fig:SVF_sigma_means_comparisons} to infer the norm from the standard deviations), parallel transport method and truncated BCH of degree 1 have comparable results, but parallel transport, as expected from the formula, is not symmetric respect to the size of the input vectors. Results of another sampling with the value of $\sigma _{\text {init}}^{0}$ and $\sigma _{\text {init}}^{1}$ are shown in figure \ref {fig:SVF_scatter_plot}}{figure.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Comparisons of the errors of numerical computation of $\mathbf  {u}_0\oplus \mathbf  {u}_1$ with the method of truncated BCH of degree 0,1 and parallel transport. Parameters' values of the random generated SVF are schematically represented in figure (a). A first set of $100$ SVF, that appears as first element in the log-composition, are generated with fixed parameters $\sigma _{\text  {gf}}^{0} = 2.0$ and $\sigma _{\text  {init}}^{0} = 1.0$; a second set of $100$ SVF, that appears as second element in the log-composition, are generated with the parameters $\sigma _{\text  {gf}}^{1} = 2.0$ and $\sigma _{\text  {init}}^{1}$ uniformly scattered in the the interval $(0.0, 2.0)$. On the x-axis fo figure (b) is shown the value of the resulting norm of $\mathbf  {u}_1$ for the chosen parameters. On the y-axes the errors for the numerical computation of the Log-composition }}{42}{figure.5.6}}
\newlabel{fig:SVF_scatter_plot}{{5.6}{42}{Comparisons of the errors of numerical computation of $\mathbf {u}_0\oplus \mathbf {u}_1$ with the method of truncated BCH of degree 0,1 and parallel transport. Parameters' values of the random generated SVF are schematically represented in figure (a). A first set of $100$ SVF, that appears as first element in the log-composition, are generated with fixed parameters $\sigma _{\text {gf}}^{0} = 2.0$ and $\sigma _{\text {init}}^{0} = 1.0$; a second set of $100$ SVF, that appears as second element in the log-composition, are generated with the parameters $\sigma _{\text {gf}}^{1} = 2.0$ and $\sigma _{\text {init}}^{1}$ uniformly scattered in the the interval $(0.0, 2.0)$. On the x-axis fo figure (b) is shown the value of the resulting norm of $\mathbf {u}_1$ for the chosen parameters. On the y-axes the errors for the numerical computation of the Log-composition}{figure.5.6}{}}
\citation{arsigny2006log}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Log-composition for synthetic SVF}{43}{subsection.5.2.2}}
\newlabel{eq:error_svf_sythetic_data}{{5.4}{43}{Log-composition for synthetic SVF}{equation.5.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Truncated BCH formula: The problem of the Jacobian matrix.}{43}{subsection.5.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Relationship between the standard deviation of the Gaussian smoother that generates the SVF and the norm of the Lie bracket. Each square contains the means of $10$ Lie bracket (left) or nested Lie bracket (right) generated with initial standard deviation equals to $2$ and standard deviation of the gaussian smoother $\sigma _{\text  {gf}}$ indicated on the axes.}}{44}{figure.5.7}}
\newlabel{fig:SVF_image_scale_bracket_versus_gaussian}{{5.7}{44}{Relationship between the standard deviation of the Gaussian smoother that generates the SVF and the norm of the Lie bracket. Each square contains the means of $10$ Lie bracket (left) or nested Lie bracket (right) generated with initial standard deviation equals to $2$ and standard deviation of the gaussian smoother $\sigma _{\text {gf}}$ indicated on the axes}{figure.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Boxplot to compare the error between truncated BCH methods of degree $0$, $1$, $1.5$ and $2$. The size of each box is $100$ and the approximation of $\mathbf  {u}_{0}\oplus \mathbf  {u}_1$ is performed with $\delimiter "026A30C \delimiter 69640972 \mathbf  {u}_{0} \delimiter 86418188 \delimiter "026A30C  = 1.0$ and $\delimiter "026A30C \delimiter 69640972 \mathbf  {u}_{0} \delimiter 86418188 \delimiter "026A30C  = 0.1$. The standard deviation of the Gaussian filter $\sigma _{\text  {gf}}$ belongs to the set $(1.0, 2.0, 3.0, 4.0)$ and the initial standard deviation is computed such that $\sigma _{\text  {init}} = \delimiter "026A30C \delimiter 69640972 \mathbf  {u} \delimiter 86418188 \delimiter "026A30C /m_{\text  {alg}}(\sigma _{\text  {gf}})$ according to the formula \ref  {eq:angular_coefficients_for_the_gf}. With this strategy we have been able to compare vector of constant norm generated with increasing values for $\sigma _{\text  {gf}}$. The numbers written in blue above each box represents the mean value of the errors. For small $\sigma _{\text  {gf}}$, an increase in the order of the approximation does not always corresponds to a decrease in the error, and in general there no great improvements can be registered when the degree is greater than 1. }}{45}{figure.5.8}}
\newlabel{fig:SVF_boxplot_comparisons_BCH}{{5.8}{45}{Boxplot to compare the error between truncated BCH methods of degree $0$, $1$, $1.5$ and $2$. The size of each box is $100$ and the approximation of $\mathbf {u}_{0}\oplus \mathbf {u}_1$ is performed with $\euclideanMetric {\mathbf {u}_{0}} = 1.0$ and $\euclideanMetric {\mathbf {u}_{0}} = 0.1$. The standard deviation of the Gaussian filter $\sigma _{\text {gf}}$ belongs to the set $(1.0, 2.0, 3.0, 4.0)$ and the initial standard deviation is computed such that $\sigma _{\text {init}} = \euclideanMetric {\mathbf {u}}/m_{\text {alg}}(\sigma _{\text {gf}})$ according to the formula \ref {eq:angular_coefficients_for_the_gf}. With this strategy we have been able to compare vector of constant norm generated with increasing values for $\sigma _{\text {gf}}$. The numbers written in blue above each box represents the mean value of the errors. For small $\sigma _{\text {gf}}$, an increase in the order of the approximation does not always corresponds to a decrease in the error, and in general there no great improvements can be registered when the degree is greater than 1}{figure.5.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}A Problem for Three Brains}{45}{section.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Log-Algorithm for SVF}{45}{section.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Number of steps required to obtain convergence in for different methods utilized in the logarithm computation algorithm. The data set contains $200$ random matrices in the Lie group $SE(2)$, with Frobenius norm between $1$ and $3$. On the top it is possible to visualize the mean number of step to reach the convergence for each method.}}{46}{figure.5.9}}
\newlabel{fig:log_computation_boxplot}{{5.9}{46}{Number of steps required to obtain convergence in for different methods utilized in the logarithm computation algorithm. The data set contains $200$ random matrices in the Lie group $SE(2)$, with Frobenius norm between $1$ and $3$. On the top it is possible to visualize the mean number of step to reach the convergence for each method}{figure.5.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Empirical Evaluations of the Computational Time}{46}{section.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Relationship between the size of the figure (x-axes) and the computational time for a data set of $20$ random generated SVF. The yellow line labeled with ground represents the time of the computation of $\qopname  \relax o{exp}{\mathbf  {u}_0}\circ \qopname  \relax o{exp}{\mathbf  {u}_1}$, while the other represents the exponentiation of the numerical method for the computation of the log-composition.}}{47}{figure.5.10}}
\newlabel{fig:svf_computational_time}{{5.10}{47}{Relationship between the size of the figure (x-axes) and the computational time for a data set of $20$ random generated SVF. The yellow line labeled with ground represents the time of the computation of $\exp {\mathbf {u}_0}\circ \exp {\mathbf {u}_1}$, while the other represents the exponentiation of the numerical method for the computation of the log-composition}{figure.5.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Conclusions}{47}{section.5.6}}
\newlabel{se:conclusions}{{5.6}{47}{Conclusions}{section.5.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Further Researches}{47}{section.5.7}}
\newlabel{se:further_research}{{5.7}{47}{Further Researches}{section.5.7}{}}
\@setckpt{chapters/Ch_results}{
\setcounter{page}{48}
\setcounter{equation}{4}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{definition}{0}
\setcounter{example}{0}
\setcounter{lemma}{0}
\setcounter{observation}{0}
\setcounter{theorem}{0}
\setcounter{prop}{0}
\setcounter{algorithm}{0}
\setcounter{Item}{39}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{46}
\setcounter{section@level}{1}
}
