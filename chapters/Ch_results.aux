\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Bossa:08}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experimental Results}{31}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:results}{{5}{31}{Experimental Results}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Log-composition for $\mathfrak  {se}(2)$}{32}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Comparison of the errors for each numerical method to compute the Log-composition $dr_{0} \oplus dr_{1}$ in $\mathfrak  {se}(2)$. Truncated BCH of degrees 0,1,2, parallel transport method and Taylor method are considered for different values of the norm of $dr_{1}$ (x-axes) and norm of $dr_{0}$ (x-axes). Values of each sub-square are the average error of 500 random samples in each of the 6 sub-intervals between $0.1$ and $2.0$. Errors with BCH 0 and parallel transport method are comparable, but the parallel transport method is not symmetric and has better performance when $dr_{1}$ is small. BCH 1 and Taylor are comparable as well, but the best performance in terms of approximation is the BCH 2. Values of the sub-square under the \emph  {gray arrows} are shown in the boxplot \ref  {fig:se2_image_scale} where variance, quartiles and outliers are visualized. }}{32}{figure.5.1}}
\newlabel{fig:se2_image_scale}{{5.1}{32}{Comparison of the errors for each numerical method to compute the Log-composition $dr_{0} \oplus dr_{1}$ in $\mathfrak {se}(2)$. Truncated BCH of degrees 0,1,2, parallel transport method and Taylor method are considered for different values of the norm of $dr_{1}$ (x-axes) and norm of $dr_{0}$ (x-axes). Values of each sub-square are the average error of 500 random samples in each of the 6 sub-intervals between $0.1$ and $2.0$. Errors with BCH 0 and parallel transport method are comparable, but the parallel transport method is not symmetric and has better performance when $dr_{1}$ is small. BCH 1 and Taylor are comparable as well, but the best performance in terms of approximation is the BCH 2. Values of the sub-square under the \emph {gray arrows} are shown in the boxplot \ref {fig:se2_image_scale} where variance, quartiles and outliers are visualized}{figure.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Methods and Results}{32}{subsection.5.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Errors of the numerical methods for the computation of the Log-composition of $dr_{0} \oplus dr_{1}$ in $\mathfrak  {se}(2)$. Norm of $dr_{0}$ is in the interval $[0.37,1.05]$, norm of $dr_{1}$ in the interval $[0.1, 1.05]$ divided in 3 segments. Mean values of each box are shown in the first row in different colors. Shown data corresponds to a section of the image scale \ref  {fig:se2_image_scale}, indicated by a gray arrow. As expected all of the error means increase with the of norm of $dr_1$, but the rate of the growth is different for each method.}}{33}{figure.5.2}}
\newlabel{fig:se2_boxplot}{{5.2}{33}{Errors of the numerical methods for the computation of the Log-composition of $dr_{0} \oplus dr_{1}$ in $\mathfrak {se}(2)$. Norm of $dr_{0}$ is in the interval $[0.37,1.05]$, norm of $dr_{1}$ in the interval $[0.1, 1.05]$ divided in 3 segments. Mean values of each box are shown in the first row in different colors. Shown data corresponds to a section of the image scale \ref {fig:se2_image_scale}, indicated by a gray arrow. As expected all of the error means increase with the of norm of $dr_1$, but the rate of the growth is different for each method}{figure.5.2}{}}
\citation{misner1973gravitation}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Log-composition for SVF}{34}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Methods: random generated SVF and ground truth.}{34}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Methods and results}{34}{subsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Random generated vector field before and after the Gaussian smoother: in the first row a random generated vector field of dimension $50\times 50 \times 2$ where the value at each pixel are sampled from a random variable with normal distribution of mean $0$ and sigma $4$. The second row shows the same random vector field after a Gaussian smoothing of sigma $2$ (the code is based on the scipy library ndimage.filters.gaussian\textunderscore filter). In the last column shows the quiver of the vector field in the squared subregion of size $10\times 10$ at the point $(20,20)$. From the colorscale it is also possible to see that the values distribution of the filtered image is not anymore symmetric. }}{35}{figure.5.3}}
\newlabel{fig:SVF_gaussian_smoothing_effects}{{5.3}{35}{Random generated vector field before and after the Gaussian smoother: in the first row a random generated vector field of dimension $50\times 50 \times 2$ where the value at each pixel are sampled from a random variable with normal distribution of mean $0$ and sigma $4$. The second row shows the same random vector field after a Gaussian smoothing of sigma $2$ (the code is based on the scipy library ndimage.filters.gaussian\textunderscore filter). In the last column shows the quiver of the vector field in the squared subregion of size $10\times 10$ at the point $(20,20)$. From the colorscale it is also possible to see that the values distribution of the filtered image is not anymore symmetric}{figure.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Log composition applied to SVF from real cases}{35}{section.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Log-Algorithm for SVF}{35}{section.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Methods}{35}{subsection.5.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Results}{35}{subsection.5.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Empirical Evaluations of Computational Time}{35}{section.5.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Conclusions and Further Research}{35}{section.5.6}}
\newlabel{ch:conclusions}{{5.6}{35}{Conclusions and Further Research}{section.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Norm of random generated of SVF with initial standard deviation $\sigma _{\text  {init}}$ (on the x-axis) and Gaussian filter with standard deviation $\sigma _{\text  {gf}}$ (different colors). On the left is shown the the Frobenius norm computed on the SVF in the Lie algebra, while on the right the same norm is computed after the exponentiations. In this second case, the norm refers to the norm of the matrix data structure (DS-norm) utilized to parametrize the SVF. Each dot represents the mean of the norm of $10$ an SVF randomly generated with the parameters indicated on the axes and in the legend. We observe that the exponential bend the shape of the random SVF when the Gaussian filter is $0$ (thus we talk about an improper SVF). The decrease in the slope when $\sigma _{\text  {gf}}=0$ do not appears for any other value.}}{36}{figure.5.4}}
\newlabel{fig:SVF_sigma_means_comparisons}{{5.4}{36}{Norm of random generated of SVF with initial standard deviation $\sigma _{\text {init}}$ (on the x-axis) and Gaussian filter with standard deviation $\sigma _{\text {gf}}$ (different colors). On the left is shown the the Frobenius norm computed on the SVF in the Lie algebra, while on the right the same norm is computed after the exponentiations. In this second case, the norm refers to the norm of the matrix data structure (DS-norm) utilized to parametrize the SVF. Each dot represents the mean of the norm of $10$ an SVF randomly generated with the parameters indicated on the axes and in the legend. We observe that the exponential bend the shape of the random SVF when the Gaussian filter is $0$ (thus we talk about an improper SVF). The decrease in the slope when $\sigma _{\text {gf}}=0$ do not appears for any other value}{figure.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Norm of the Lie bracket as direct consequence of the sigma of the Gaussian smoother of respective SVF. Here put every other data!}}{36}{figure.5.5}}
\newlabel{fig:SVF_image_scale_bracket_versus_gaussian}{{5.5}{36}{Norm of the Lie bracket as direct consequence of the sigma of the Gaussian smoother of respective SVF. Here put every other data!}{figure.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Log-composition for SVF computed using numerical methods of truncated BCH of degree 0,1 and parallel transport.}}{37}{figure.5.6}}
\newlabel{fig:SVF_bch_parallel_transport}{{5.6}{37}{Log-composition for SVF computed using numerical methods of truncated BCH of degree 0,1 and parallel transport}{figure.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Log-composition for SVF; the operation $\mathbf  {u}_0\oplus \mathbf  {u}_1$ is computed using numerical methods of truncated BCH of degree 0,1 and parallel transport. Respective standard deviation of the random generated SVF given by $\sigma _0$ and $\sigma _1$, ranges between $0.3$ and $2.0$ for $\sigma _0$ and between $0.2$ and $2.0$ for $\sigma _1$. Each value in the image scale is the mean of $10$ results of the log-computation of random SVF generated with given standard deviation. For lower values of $\mathbf  {u}_1$, that in the image registration algorithms are given by the update, parallel transport method and truncated BCH of degree 1 have comparable results. We can also notice that for truncated BCH methods the results are symmetric, while for parallel transport, as expected from the formula, results are not symmetric respect to the size of the input vectors. }}{37}{figure.5.7}}
\newlabel{fig:SVF_image_scale}{{5.7}{37}{Log-composition for SVF; the operation $\mathbf {u}_0\oplus \mathbf {u}_1$ is computed using numerical methods of truncated BCH of degree 0,1 and parallel transport. Respective standard deviation of the random generated SVF given by $\sigma _0$ and $\sigma _1$, ranges between $0.3$ and $2.0$ for $\sigma _0$ and between $0.2$ and $2.0$ for $\sigma _1$. Each value in the image scale is the mean of $10$ results of the log-computation of random SVF generated with given standard deviation. For lower values of $\mathbf {u}_1$, that in the image registration algorithms are given by the update, parallel transport method and truncated BCH of degree 1 have comparable results. We can also notice that for truncated BCH methods the results are symmetric, while for parallel transport, as expected from the formula, results are not symmetric respect to the size of the input vectors}{figure.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Log-composition for SVF computed using numerical methods of truncated BCH of degree 0,1 and parallel transport, represented in a boxplot.}}{38}{figure.5.8}}
\newlabel{fig:SVF_boxplot}{{5.8}{38}{Log-composition for SVF computed using numerical methods of truncated BCH of degree 0,1 and parallel transport, represented in a boxplot}{figure.5.8}{}}
\@setckpt{chapters/Ch_results}{
\setcounter{page}{39}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{8}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{definition}{0}
\setcounter{example}{0}
\setcounter{lemma}{0}
\setcounter{observation}{0}
\setcounter{theorem}{0}
\setcounter{prop}{0}
\setcounter{algorithm}{0}
\setcounter{Item}{47}
\setcounter{Hfootnote}{2}
\setcounter{bookmark@seq@number}{43}
\setcounter{section@level}{1}
}
